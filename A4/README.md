# Experiment 4: Ensemble Prediction and Decision Tree Model Evaluation

## Aim
 To build classifiers such as Decision Tree, AdaBoost, Gradient Boosting, XGBoost, Random Forest,
 and Stacked Models (using SVM, Na¨ıve Bayes, Decision Tree) and evaluate their performance
 through 5-Fold Cross-Validation and hyperparameter tuning.


## Tools and Libraries Used
| Library| Purpose |
|-|-|
| `numpy` | Numerical computations |
| `pandas` | Data handling and preprocessing |
| `scipy` | Scientific and statistical analysis |
| `scikit-learn` | Machine learning algorithms and evaluation |
| `matplotlib` | Data visualization |
| `seaborn` | Advanced visualizations |

## Files Included

| Filename | Description |
|-|-|
| `ML_A4.ipynb` | Jupyter notebook with all code and results |
| `README.md` | This file – experiment overview and usage |
| `Report4.pdf` | Report explaining the experiment's results  |



##  How to Run

### Prerequisites

- Python 3.8 or higher
- Jupyter Notebook or any IDE (VSCode, PyCharm, etc.)

### Installation Steps

1. **Clone the repository**

2. **Install Dependencies**

3. **Run the notebook(s)**
